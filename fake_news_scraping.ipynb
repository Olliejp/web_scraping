{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "composed-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-northeast",
   "metadata": {},
   "source": [
    "# Web scraping fake news headlines related to covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-lawyer",
   "metadata": {},
   "source": [
    "The ultimate goal is to build an intelligent system which can automatically montor, flag and track trends in COVAX fake news. To do so, we need to find text data related to fake and real news. As a starting point I am checking Poynter - https://www.poynter.org/. Poynter has a list of over 10,000 fake afticles which they have fact checked. The problem is, this data exists on their webiste and is not downloadable. Therefore we need to scrape their website. Their data is split between 78 pages which need to be clicked through, so when scraping, we need to loop through these pages. Since we want to train a model specifically for vaccines, we will filter the URL query for vaccines only. We could scrape their entire website for covid missinformation, however we also need to find a similar number of true articles for training the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "thirty-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number 3 of 78 scraped\n",
      "Page number 6 of 78 scraped\n",
      "Page number 9 of 78 scraped\n",
      "Page number 12 of 78 scraped\n",
      "Page number 15 of 78 scraped\n",
      "Page number 18 of 78 scraped\n",
      "Page number 21 of 78 scraped\n",
      "Page number 24 of 78 scraped\n",
      "Page number 27 of 78 scraped\n",
      "Page number 30 of 78 scraped\n",
      "Page number 33 of 78 scraped\n",
      "Page number 36 of 78 scraped\n",
      "Page number 39 of 78 scraped\n",
      "Page number 42 of 78 scraped\n",
      "Page number 45 of 78 scraped\n",
      "Page number 48 of 78 scraped\n",
      "Page number 51 of 78 scraped\n",
      "Page number 54 of 78 scraped\n",
      "Page number 57 of 78 scraped\n",
      "Page number 60 of 78 scraped\n",
      "Page number 63 of 78 scraped\n",
      "Page number 66 of 78 scraped\n",
      "Page number 69 of 78 scraped\n",
      "Page number 72 of 78 scraped\n",
      "Page number 75 of 78 scraped\n",
      "Page number 78 of 78 scraped\n"
     ]
    }
   ],
   "source": [
    "headers = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.192 Safari/537.36'\n",
    "\n",
    "label = []\n",
    "headline = []\n",
    "\n",
    "for i in range(1, 79):\n",
    "    URL = 'https://www.poynter.org/ifcn-covid-19-misinformation/page/{}/?search_terms=vaccine'.format(i)\n",
    "    page = requests.get(URL, headers={'User-Agent': headers})\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    elems = soup.find_all('h2', class_=\"entry-title\")\n",
    "\n",
    "    for header in elems:\n",
    "        label.append(header.text.split(':')[0].strip(\"\\n\").strip())\n",
    "        headline.append(header.text.split(':')[1].strip(\"\\n\").strip())\n",
    "    if i % 3 == 0:\n",
    "        print(\"Page number {} of 78 scraped\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "medieval-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(label, headline)), \n",
    "               columns =['label', 'headline']) \n",
    "df = df.drop_duplicates(subset=['headline'])\n",
    "\n",
    "keep_labels = ['FALSE', 'False', \n",
    "               'Misleading', 'MISLEADING', \n",
    "               'No evidence', 'Missing context', \n",
    "               'Partially false', 'misleading ', \n",
    "               'mostly false', 'NO EVIDENCE',\n",
    "               'Mostly false', 'Manipulated', \n",
    "               'Misleading/False', 'Not true', \n",
    "               'Mainly false', ]\n",
    "\n",
    "df = df[df['label'].isin(keep_labels)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "loved-judge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1119, 2)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-chancellor",
   "metadata": {},
   "source": [
    "We have 1119 news headlines related to fake vaccine news. Below, we print 5 at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "healthy-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: The measles-mumps-rubella vaccine reduces the severity of COVID-19.\n",
      "Label: No evidence\n",
      "\n",
      "Headline: Vaccines killed 181 people in the United States\n",
      "Label: FALSE\n",
      "\n",
      "Headline: We do not need a vaccine. We need a body that can resist this and any other virus\n",
      "Label: FALSE\n",
      "\n",
      "Headline: A sharp increase in COVID-19 cases in England and Israel after the rollout of the vaccines proves the inefficacy of the vaccine\n",
      "Label: MISLEADING\n",
      "\n",
      "Headline: India is suing Microsoft founder Bill Gates because of his vaccine against coronavirus that killed 77,000 girls.\n",
      "Label: FALSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = [randint(0, len(df)) for x in range(5)]\n",
    "\n",
    "for i in x:\n",
    "    print(\"Headline: {}\".format(df.loc[i]['headline']))\n",
    "    print(\"Label: {}\\n\".format(df.loc[i]['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-repeat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
